{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39ff9508-370b-469d-86dc-e457257e7669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import math as m\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import subprocess\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# sys.path.append(r\"C:\\Users\\June Means\\.conda\\envs\\CVenv\\Lib\\site-packages\\cv2\") # This seems to be an issue uniquely with my conda installation\n",
    "# sys.path.append(r\"C:\\Users\\June Means\\.conda\\envs\\CVenv\\Lib\\site-packages\\openpyxl\")\n",
    "import cv2\n",
    "import struct\n",
    "import threading\n",
    "from collections import deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90f4733f-5853-46a7-8aee-11cc2012d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "FFMPEG_PATH= r\"C:\\Program Files\\ffmpeg-8.0-full_build\\bin\\ffmpeg.exe\" # The path of the FFMPEG.exe on the system\n",
    "FFPROBE_PATH= r\"C:\\Program Files\\ffmpeg-8.0-full_build\\bin\\ffprobe.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f146fa7-f2bd-4d1c-bcf4-20f1b20b526d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletedProcess(args=['ffprobe', '-v', 'error', '-select_streams', 'v:0', '-show_entries', 'stream=r_frame_rate,duration', '-of', 'default=noprint_wrappers=1:nokey=1', 'C:\\\\Users\\\\jjmmc\\\\Downloads\\\\TRAP2-5-208-L3-output_with_overlaycollisions_id1.mp4'], returncode=0, stdout='29583/1000\\n9.938140\\n', stderr='')\n",
      "(29.583, 9.93814)\n",
      "Video opened successfully\n",
      "Total frames: 25137\n",
      "FPS: 29.59517818093909\n",
      "CompletedProcess(args=['ffprobe', '-v', 'error', '-select_streams', 'v:0', '-show_entries', 'stream=r_frame_rate,duration', '-of', 'default=noprint_wrappers=1:nokey=1', 'C:\\\\Users\\\\jjmmc\\\\Downloads\\\\20241101_TRAP2social_5VLS_M_L5_TRAP2156+157.mp4'], returncode=0, stdout='60/1\\n849.361300\\n', stderr='')\n",
      "\n",
      "Total sampled frames: 120\n",
      "Frame shape: (1080, 1920, 3)\n",
      "Frame dtype: uint8\n",
      "Array shape: (120, 1080, 1920, 3)\n",
      "Background shape: (1080, 1920, 3)\n",
      "Background dtype: uint8\n",
      "Background min/max: 0/255\n",
      "Image write success: True\n"
     ]
    }
   ],
   "source": [
    "def ffmpeg_frame_probe(video_path):\n",
    "    \"\"\"\n",
    "    Probe a video file to get its frames per second (fps) using ffprobe.\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to video file\n",
    "        \n",
    "    Returns:\n",
    "        float: The fps of the video\n",
    "    \"\"\"\n",
    "    cmd = [\n",
    "        \"ffprobe\",\n",
    "        \"-v\", \"error\",\n",
    "        \"-select_streams\", \"v:0\",\n",
    "        \"-show_entries\", \"stream=r_frame_rate,duration\",  # Get frame rate and duration\n",
    "        \"-of\", \"default=noprint_wrappers=1:nokey=1\",\n",
    "        video_path\n",
    "    ]\n",
    "    try:\n",
    "        result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
    "        # ffprobe returns frame rate as a fraction (e.g., \"30000/1001\" or \"30/1\")\n",
    "        print(result)\n",
    "        # fps_str = result.stdout.strip()\n",
    "        fps_str = result.stdout.splitlines()[0].strip()\n",
    "        duration_str = result.stdout.splitlines()[1].strip()\n",
    "        # Parse the fraction\n",
    "        if '/' in fps_str:\n",
    "            numerator, denominator = fps_str.split('/')\n",
    "            fps = float(numerator) / float(denominator)\n",
    "        else:\n",
    "            fps = float(fps_str)\n",
    "\n",
    "        duration = float(duration_str)\n",
    "        return fps, duration\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error during ffprobe execution: {e}\")\n",
    "        print(f\"stderr: {e.stderr}\")\n",
    "        print(\"A assumed fps of 29.595 has been returned. Duration cannot be assumed and so 0 is returned\")\n",
    "        return(29.595, 0)\n",
    "\n",
    "print(ffmpeg_frame_probe(r\"C:\\Users\\jjmmc\\Downloads\\TRAP2-5-208-L3-output_with_overlaycollisions_id1.mp4\"))\n",
    "\n",
    "# class video_preprocessing():\n",
    "    # def __init__(self):\n",
    "    #     self.var =0\n",
    "def animal_cropper(processing_video_path, frame_span = 3600):\n",
    "    \"\"\"\n",
    "    This removes the animal from a video to obtain an average that should reflect the background of the video\n",
    "    This works by masking out the are of highest movement and\n",
    "    \"\"\"\n",
    "    # sample a spaced out number of frames \n",
    "    # Sample every 30 frames (adjust based on your video)\n",
    "    cap = cv2.VideoCapture(processing_video_path)\n",
    "    \n",
    "    # Check if video opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video\")\n",
    "    else:\n",
    "        print(f\"Video opened successfully\")\n",
    "        print(f\"Total frames: {int(cap.get(cv2.CAP_PROP_FRAME_COUNT))}\")\n",
    "        print(f\"FPS: {cap.get(cv2.CAP_PROP_FPS)}\")\n",
    "    fps, duration = ffmpeg_frame_probe(processing_video_path)\n",
    "    \n",
    "    sampled_frames = []\n",
    "    frame_idx = 0\n",
    "    \n",
    "    if duration*fps < frame_span:\n",
    "        print(f\"This video is less than {frame_span} frames long. Thus there may be too few samples to properly construct the background.\")\n",
    "        sample_interval = int((duration*fps)/30)\n",
    "    else:\n",
    "        sample_interval = 30\n",
    "    \n",
    "    while cap.isOpened() and frame_idx < frame_span:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if frame_idx % sample_interval == 0:\n",
    "            sampled_frames.append(frame)        \n",
    "        frame_idx += 1\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    print(f\"\\nTotal sampled frames: {len(sampled_frames)}\")\n",
    "    \n",
    "    if len(sampled_frames) == 0:\n",
    "        print(\"ERROR: No frames were sampled!\")\n",
    "    else:\n",
    "        print(f\"Frame shape: {sampled_frames[0].shape}\")\n",
    "        print(f\"Frame dtype: {sampled_frames[0].dtype}\")\n",
    "        \n",
    "        # Convert to numpy array first\n",
    "        frames_array = np.array(sampled_frames)\n",
    "        print(f\"Array shape: {frames_array.shape}\")\n",
    "        \n",
    "        # Compute median\n",
    "        background = np.median(frames_array, axis=0).astype(np.uint8)\n",
    "        background = np.mean(frames_array, axis=0).astype(np.uint8)\n",
    "        print(f\"Background shape: {background.shape}\")\n",
    "        print(f\"Background dtype: {background.dtype}\")\n",
    "        print(f\"Background min/max: {background.min()}/{background.max()}\")\n",
    "        \n",
    "        # Check for NaN\n",
    "        if np.isnan(background).any():\n",
    "            print(\"WARNING: Background contains NaN values!\")\n",
    "        else:\n",
    "            success = cv2.imwrite('output_image.jpeg', background)\n",
    "            print(f\"Image write success: {success}\")\n",
    "\n",
    "def roi_finder(processing_video_path, threshold1 =100, threshold2= 200):\n",
    "    \"\"\"\n",
    "    This uses edge detection to find the dimensions of the box, the location of the nest and of the loom. If it fails to find a good fit it will change threshold parameters until it gives up\n",
    "    \"\"\"\n",
    "    low_thresh = np.arange(20,180, 20)\n",
    "    high_thresh = np.arange(40,200, 20)\n",
    "\n",
    "    # for low,high in zip(low_thresh, high_thresh):\n",
    "        \n",
    "    #     # image = cv2.imread(processing_video_path)\n",
    "    #     # edges = cv2.Canny(image, low, high)\n",
    "        \n",
    "        \n",
    "        \n",
    "    #     success = cv2.imwrite(f'output_edges{low}-{high}.jpeg', edges)\n",
    "    #     print(f\"Image write success: {success}\")\n",
    "\n",
    "    # for i in range(1,7,2):\n",
    "    #     image = cv2.imread(processing_video_path, cv2.IMREAD_GRAYSCALE)\n",
    "    #     edges =cv2.Laplacian(image, -1, ksize=i)\n",
    "    #     success = cv2.imwrite(f'output_edges_{i}.jpeg', edges)\n",
    "        # success = cv2.imwrite(f'output_edges{low}-{high}.jpeg', edges)\n",
    "    \n",
    "    image = cv2.imread(processing_video_path)\n",
    "    blur = cv2.GaussianBlur(image, (5, 5), 1.4)\n",
    "    edges = cv2.Canny(blur, 20, 40)        \n",
    "        \n",
    "    contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Sort contours by area and pick the largest one (assuming it's your target rectangle)\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        print(len(contours))\n",
    "        rect = cv2.minAreaRect(largest_contour)\n",
    "        \n",
    "        box = cv2.boxPoints(rect)\n",
    "        box = np.int32(box)\n",
    "        \n",
    "        image_bgr = image.copy()\n",
    "        cv2.drawContours(image_bgr, [box], 0, (0, 0, 255), 2)\n",
    "        \n",
    "        cv2.imshow('Fitted Rectangle', image_bgr)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    # This is a bit mathy but one of the things that doesn't change as a result of perspective shifts or even \n",
    "\n",
    "\n",
    "\n",
    "# animal_cropper(r\"C:\\Users\\jjmmc\\Downloads\\20250113_socialTRAP2_5VLS_208+209.mp4\")\n",
    "animal_cropper(r\"C:\\Users\\jjmmc\\Downloads\\20241101_TRAP2social_5VLS_M_L5_TRAP2156+157.mp4\")\n",
    "# roi_finder(r\"C:\\Users\\jjmmc\\Documents\\FileTreeShenanigans\\output_image.jpeg\")\n",
    "\n",
    "\n",
    "def angle_correction(inter_video_path):\n",
    "    #check if the box angle\n",
    "    angle=30\n",
    "    # ffmpeg -i input.mp4 -vf \"rotate=angle*PI/180\" output.mp4\n",
    "\n",
    "    cmd = [\n",
    "        \"ffmpeg\",\n",
    "        \"-v\", \"error\",  # Hide unnecessary output\n",
    "        \"-i\", inter_video_path,\n",
    "        \"-vf\",\n",
    "        f\"rotate={angle}*PI/180\",\n",
    "        \"output_temp.mp4\",\n",
    "        # \"&&\", \"mv\", #Then if successful move the output to the input\n",
    "        # \"output_temp.mp4\", inter_video_path\n",
    "    ]\n",
    "    print(cmd)\n",
    "    try:\n",
    "        result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
    "        # ffprobe returns frame rate as a fraction (e.g., \"30000/1001\" or \"30/1\")\n",
    "        \n",
    "        \n",
    "        # Parse the fraction\n",
    "        # if '/' in fps_str:\n",
    "        #     numerator, denominator = fps_str.split('/')\n",
    "        #     fps = float(numerator) / float(denominator)\n",
    "        # else:\n",
    "        #     fps = float(fps_str)\n",
    "            \n",
    "        # return fps\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error during ffprobe execution: {e}\")\n",
    "        print(f\"stderr: {e.stderr}\")\n",
    "        print(\"A assumed fps of 29.595 has been returned\")\n",
    "        return(29.595)\n",
    "\n",
    "def show_roi():\n",
    "    \"\"\"\n",
    "    This is a visualization of the ROIs on the first frame of the video. \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "# angle_correction(r\"C:\\Users\\jjmmc\\Downloads\\TRAP2-5-208-L3-output_with_overlaycollisions_id1.mp4\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c431a2d4-d5b4-4b15-8dba-cd4d6aaa0b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "NEGATIVE SPACE DETECTION\n",
      "======================================================================\n",
      "Detected 5982 lines\n",
      "Kept 4219 lines after filtering\n",
      "Found 7912 regions in negative space\n",
      "\n",
      "Top candidate regions:\n",
      "  1. Area: 14.3%, Variance: 522.7, Score: 0.39\n",
      "\n",
      "Selected region: 14.3% of frame\n",
      "Found 197 lines bordering the region\n",
      "Border lines form 18 angle clusters\n",
      "\n",
      "Trying border clusters 0,3: 50 + 16 lines, angles 174.7° and 87.6° (diff: 87.1°)\n",
      "  Box area: 13.4% of frame\n",
      "  Confidence: 0.42\n",
      "\n",
      "Trying border clusters 1,3: 21 + 16 lines, angles 4.0° and 87.6° (diff: 83.6°)\n",
      "  Box area: 16.3% of frame\n",
      "  Confidence: 0.39\n",
      "\n",
      "✓ Detection successful!\n",
      "  Confidence: 0.42\n",
      "  Center: (1069.5, 761.7)\n",
      "  Dimensions: 508.9 x 546.7\n",
      "  Rotation: 86.0°\n",
      "  Area: 13.4% of frame\n",
      "\n",
      "✓ Visualization saved to negative_space_detection.png\n",
      "\n",
      "======================================================================\n",
      "DETECTED CORNERS:\n",
      "======================================================================\n",
      "  Corner 1: (779.1, 526.9)\n",
      "  Corner 2: (1324.5, 488.9)\n",
      "  Corner 3: (1359.8, 996.5)\n",
      "  Corner 4: (814.5, 1034.5)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, Optional, List\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class RotatedBoxROI:\n",
    "    \"\"\"Container for detected rotated box region of interest.\"\"\"\n",
    "    corners: np.ndarray\n",
    "    center: Tuple[float, float]\n",
    "    width: float\n",
    "    height: float\n",
    "    angle: float\n",
    "    confidence: float\n",
    "\n",
    "\n",
    "def detect_box_negative_space(image: np.ndarray, \n",
    "                               min_area_ratio: float = 1/6,\n",
    "                               visualize: bool = False) -> Optional[RotatedBoxROI]:\n",
    "    \"\"\"\n",
    "    Negative space approach: Find smooth regions enclosed by Hough lines.\n",
    "    \n",
    "    Strategy:\n",
    "    1. Detect all lines with Hough transform\n",
    "    2. Draw lines on a blank canvas to create enclosed regions\n",
    "    3. Find large smooth regions (the box interior)\n",
    "    4. Use the lines that border these regions as the box edges\n",
    "    5. Construct bounding box from border lines\n",
    "    \n",
    "    Args:\n",
    "        image: BGR image\n",
    "        min_area_ratio: Minimum box area as fraction of image area\n",
    "        visualize: Whether to save visualizations\n",
    "    \n",
    "    Returns:\n",
    "        RotatedBoxROI object or None if detection fails\n",
    "    \"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    # Preprocessing\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Adaptive histogram equalization\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))\n",
    "    enhanced = clahe.apply(gray)\n",
    "    \n",
    "    # Gaussian blur\n",
    "    blur = cv2.GaussianBlur(enhanced, (5, 5), 1.4)\n",
    "    \n",
    "    # Canny edge detection\n",
    "    edges = cv2.Canny(blur, 30, 50, apertureSize=3)\n",
    "    cv2.imshow('canny edge detection', edges)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    # Dilate edges slightly to connect nearby segments\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "    \n",
    "    # Hough line detection\n",
    "    lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi/180, threshold=50,\n",
    "                           minLineLength=60, maxLineGap=20)\n",
    "    \n",
    "    if lines is None:\n",
    "        print(\"No lines detected!\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Detected {len(lines)} lines\")\n",
    "    \n",
    "    # Filter short lines and store line properties\n",
    "    lines_data = []\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "        \n",
    "        if length < 80:\n",
    "            continue\n",
    "        \n",
    "        lines_data.append({\n",
    "            'line': line[0],\n",
    "            'length': length\n",
    "        })\n",
    "    \n",
    "    print(f\"Kept {len(lines_data)} lines after filtering\")\n",
    "    \n",
    "    if len(lines_data) < 4:\n",
    "        print(\"Insufficient lines\")\n",
    "        return None\n",
    "    \n",
    "    # Create a canvas with all lines drawn\n",
    "    line_canvas = np.zeros((h, w), dtype=np.uint8)\n",
    "    \n",
    "    for line_data in lines_data:\n",
    "        x1, y1, x2, y2 = line_data['line']\n",
    "        cv2.line(line_canvas, (x1, y1), (x2, y2), 255, 2)\n",
    "    \n",
    "    if visualize:\n",
    "        cv2.imwrite('/home/claude/line_canvas.png', line_canvas)\n",
    "    \n",
    "    # Invert to get negative space (regions enclosed by lines)\n",
    "    negative_space = cv2.bitwise_not(line_canvas)\n",
    "    \n",
    "    # Find connected components (regions)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(\n",
    "        negative_space, connectivity=8\n",
    "    )\n",
    "    \n",
    "    print(f\"Found {num_labels - 1} regions in negative space\")\n",
    "    \n",
    "    # Analyze regions to find smooth areas (potential box interior)\n",
    "    # The box interior should be:\n",
    "    # 1. Large area (meets min_area_ratio)\n",
    "    # 2. Located in central portion of image\n",
    "    # 3. Has smooth texture (low variance in original image)\n",
    "    \n",
    "    img_area = h * w\n",
    "    candidate_regions = []\n",
    "    \n",
    "    for label in range(1, num_labels):  # Skip background (label 0)\n",
    "        area = stats[label, cv2.CC_STAT_AREA]\n",
    "        \n",
    "        # Must be at least min_area_ratio of image\n",
    "        if area < min_area_ratio * img_area:\n",
    "            continue\n",
    "        \n",
    "        # Must not be too large (avoid selecting entire frame)\n",
    "        if area > 0.9 * img_area:\n",
    "            continue\n",
    "        \n",
    "        # Create mask for this region\n",
    "        region_mask = (labels == label).astype(np.uint8) * 255\n",
    "        \n",
    "        # Calculate smoothness (inverse of variance in the region)\n",
    "        region_pixels = gray[region_mask > 0]\n",
    "        if len(region_pixels) > 0:\n",
    "            variance = np.var(region_pixels)\n",
    "            smoothness = 1.0 / (1.0 + variance / 100.0)\n",
    "        else:\n",
    "            smoothness = 0\n",
    "        \n",
    "        # Calculate centrality (how close to image center)\n",
    "        cx, cy = centroids[label]\n",
    "        center_dist = np.sqrt((cx - w/2)**2 + (cy - h/2)**2)\n",
    "        max_dist = np.sqrt((w/2)**2 + (h/2)**2)\n",
    "        centrality = 1.0 - (center_dist / max_dist)\n",
    "        \n",
    "        # Combined score\n",
    "        area_score = min(area / (0.5 * img_area), 1.0)\n",
    "        score = 0.4 * area_score + 0.3 * smoothness + 0.3 * centrality\n",
    "        \n",
    "        candidate_regions.append({\n",
    "            'label': label,\n",
    "            'area': area,\n",
    "            'mask': region_mask,\n",
    "            'variance': variance,\n",
    "            'smoothness': smoothness,\n",
    "            'centrality': centrality,\n",
    "            'score': score,\n",
    "            'centroid': (cx, cy)\n",
    "        })\n",
    "    \n",
    "    if not candidate_regions:\n",
    "        print(\"No candidate regions found\")\n",
    "        return None\n",
    "    \n",
    "    # Sort by score and take the best\n",
    "    candidate_regions.sort(key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    print(f\"\\nTop candidate regions:\")\n",
    "    for i, region in enumerate(candidate_regions[:3]):\n",
    "        print(f\"  {i+1}. Area: {region['area']/img_area*100:.1f}%, \"\n",
    "              f\"Variance: {region['variance']:.1f}, \"\n",
    "              f\"Score: {region['score']:.2f}\")\n",
    "    \n",
    "    best_region = candidate_regions[0]\n",
    "    region_mask = best_region['mask']\n",
    "    \n",
    "    print(f\"\\nSelected region: {best_region['area']/img_area*100:.1f}% of frame\")\n",
    "    \n",
    "    # Find the lines that border this region\n",
    "    # Dilate the region slightly and subtract to get boundary\n",
    "    kernel_dilate = np.ones((5, 5), np.uint8)\n",
    "    dilated_region = cv2.dilate(region_mask, kernel_dilate, iterations=1)\n",
    "    boundary = cv2.subtract(dilated_region, region_mask)\n",
    "    \n",
    "    # Find which lines intersect with this boundary\n",
    "    border_lines = []\n",
    "    \n",
    "    for line_data in lines_data:\n",
    "        x1, y1, x2, y2 = line_data['line']\n",
    "        \n",
    "        # Create a temporary line mask\n",
    "        temp_line = np.zeros((h, w), dtype=np.uint8)\n",
    "        cv2.line(temp_line, (x1, y1), (x2, y2), 255, 2)\n",
    "        \n",
    "        # Check overlap with boundary\n",
    "        overlap = cv2.bitwise_and(temp_line, boundary)\n",
    "        overlap_pixels = np.sum(overlap > 0)\n",
    "        \n",
    "        # If line has significant overlap with boundary, it's a border line\n",
    "        if overlap_pixels > 10:  # At least 10 pixels overlap\n",
    "            border_lines.append(line_data)\n",
    "    \n",
    "    print(f\"Found {len(border_lines)} lines bordering the region\")\n",
    "    \n",
    "    if len(border_lines) < 4:\n",
    "        print(\"Insufficient border lines\")\n",
    "        return None\n",
    "    \n",
    "    # Cluster border lines by angle\n",
    "    angles = []\n",
    "    for line_data in border_lines:\n",
    "        x1, y1, x2, y2 = line_data['line']\n",
    "        angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi\n",
    "        angle = angle % 180\n",
    "        angles.append(angle)\n",
    "        line_data['angle'] = angle\n",
    "    \n",
    "    # Simple angle clustering with 10 degree bins\n",
    "    angle_bins = {}\n",
    "    bin_size = 10.0\n",
    "    \n",
    "    for line_data in border_lines:\n",
    "        angle = line_data['angle']\n",
    "        bin_id = int(angle / bin_size)\n",
    "        \n",
    "        if bin_id not in angle_bins:\n",
    "            angle_bins[bin_id] = []\n",
    "        angle_bins[bin_id].append(line_data)\n",
    "    \n",
    "    # Find two largest clusters\n",
    "    cluster_sizes = [(bin_id, len(lines)) for bin_id, lines in angle_bins.items()]\n",
    "    cluster_sizes.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    if len(cluster_sizes) < 2:\n",
    "        print(\"Need at least 2 angle clusters in border lines\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Border lines form {len(cluster_sizes)} angle clusters\")\n",
    "    \n",
    "    # Try to find perpendicular clusters\n",
    "    best_box = None\n",
    "    best_confidence = 0\n",
    "    \n",
    "    for i in range(min(3, len(cluster_sizes))):\n",
    "        for j in range(i+1, min(4, len(cluster_sizes))):\n",
    "            bin1_id, size1 = cluster_sizes[i]\n",
    "            bin2_id, size2 = cluster_sizes[j]\n",
    "            \n",
    "            cluster1 = angle_bins[bin1_id]\n",
    "            cluster2 = angle_bins[bin2_id]\n",
    "            \n",
    "            angle1_avg = np.mean([l['angle'] for l in cluster1])\n",
    "            angle2_avg = np.mean([l['angle'] for l in cluster2])\n",
    "            \n",
    "            angle_diff = abs(angle1_avg - angle2_avg)\n",
    "            if angle_diff > 90:\n",
    "                angle_diff = 180 - angle_diff\n",
    "            \n",
    "            # Check perpendicularity\n",
    "            if not (70 < angle_diff < 110):\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\nTrying border clusters {i},{j}: {size1} + {size2} lines, \"\n",
    "                  f\"angles {angle1_avg:.1f}° and {angle2_avg:.1f}° (diff: {angle_diff:.1f}°)\")\n",
    "            \n",
    "            # Instead of using all border lines, find the extreme lines in each cluster\n",
    "            # that bound the smooth region\n",
    "            \n",
    "            img_center = np.array([w / 2, h / 2])\n",
    "            \n",
    "            # For each cluster, find the lines that are furthest from the center\n",
    "            # in the perpendicular direction to the cluster's angle\n",
    "            def get_distance_from_center(line_data):\n",
    "                \"\"\"Get distance of line midpoint from image center.\"\"\"\n",
    "                x1, y1, x2, y2 = line_data['line']\n",
    "                mid = np.array([(x1 + x2) / 2, (y1 + y2) / 2])\n",
    "                return np.linalg.norm(mid - img_center)\n",
    "            \n",
    "            # For cluster 1, get perpendicular direction\n",
    "            perp_angle1 = (angle1_avg + 90) % 180\n",
    "            perp_rad1 = np.radians(perp_angle1)\n",
    "            perp_vec1 = np.array([np.cos(perp_rad1), np.sin(perp_rad1)])\n",
    "            \n",
    "            # Get signed distances for cluster 1 lines\n",
    "            signed_dists1 = []\n",
    "            for line_data in cluster1:\n",
    "                x1, y1, x2, y2 = line_data['line']\n",
    "                mid = np.array([(x1 + x2) / 2, (y1 + y2) / 2])\n",
    "                vec_to_mid = mid - img_center\n",
    "                signed_dist = np.dot(vec_to_mid, perp_vec1)\n",
    "                signed_dists1.append((line_data, signed_dist))\n",
    "            \n",
    "            signed_dists1.sort(key=lambda x: x[1])\n",
    "            edge1_a = signed_dists1[0][0]['line']   # Most negative\n",
    "            edge1_b = signed_dists1[-1][0]['line']  # Most positive\n",
    "            \n",
    "            # For cluster 2, same approach\n",
    "            perp_angle2 = (angle2_avg + 90) % 180\n",
    "            perp_rad2 = np.radians(perp_angle2)\n",
    "            perp_vec2 = np.array([np.cos(perp_rad2), np.sin(perp_rad2)])\n",
    "            \n",
    "            signed_dists2 = []\n",
    "            for line_data in cluster2:\n",
    "                x1, y1, x2, y2 = line_data['line']\n",
    "                mid = np.array([(x1 + x2) / 2, (y1 + y2) / 2])\n",
    "                vec_to_mid = mid - img_center\n",
    "                signed_dist = np.dot(vec_to_mid, perp_vec2)\n",
    "                signed_dists2.append((line_data, signed_dist))\n",
    "            \n",
    "            signed_dists2.sort(key=lambda x: x[1])\n",
    "            edge2_a = signed_dists2[0][0]['line']\n",
    "            edge2_b = signed_dists2[-1][0]['line']\n",
    "            \n",
    "            # Find intersections of these 4 edge lines\n",
    "            def line_intersection(line1, line2):\n",
    "                \"\"\"Find intersection of two lines.\"\"\"\n",
    "                x1, y1, x2, y2 = line1\n",
    "                x3, y3, x4, y4 = line2\n",
    "                \n",
    "                denom = (x1 - x2) * (y3 - y4) - (y1 - y2) * (x3 - x4)\n",
    "                \n",
    "                if abs(denom) < 1e-6:\n",
    "                    return None\n",
    "                \n",
    "                t = ((x1 - x3) * (y3 - y4) - (y1 - y3) * (x3 - x4)) / denom\n",
    "                \n",
    "                x = x1 + t * (x2 - x1)\n",
    "                y = y1 + t * (y2 - y1)\n",
    "                \n",
    "                return np.array([x, y])\n",
    "            \n",
    "            # Find all 4 corners\n",
    "            corners = []\n",
    "            for e1 in [edge1_a, edge1_b]:\n",
    "                for e2 in [edge2_a, edge2_b]:\n",
    "                    corner = line_intersection(e1, e2)\n",
    "                    if corner is not None:\n",
    "                        corners.append(corner)\n",
    "            \n",
    "            if len(corners) != 4:\n",
    "                print(f\"  Got {len(corners)} corners, need 4\")\n",
    "                continue\n",
    "            \n",
    "            corners = np.array(corners, dtype=np.float32)\n",
    "            \n",
    "            # Get rect from corners\n",
    "            rect = cv2.minAreaRect(corners)\n",
    "            center, (width, height), angle_rot = rect\n",
    "            box_points = cv2.boxPoints(rect)\n",
    "            \n",
    "            area = width * height\n",
    "            area_ratio = area / img_area\n",
    "            \n",
    "            print(f\"  Box area: {area_ratio*100:.1f}% of frame\")\n",
    "            \n",
    "            # Validate\n",
    "            if area_ratio < min_area_ratio or area_ratio > 0.9:\n",
    "                continue\n",
    "            \n",
    "            # Calculate confidence\n",
    "            area_score = min(area_ratio / 0.4, 1.0)\n",
    "            angle_score = 1.0 - abs(angle_diff - 90) / 20\n",
    "            region_score = best_region['smoothness']\n",
    "            \n",
    "            confidence = 0.3 * area_score + 0.3 * angle_score + 0.4 * region_score\n",
    "            \n",
    "            print(f\"  Confidence: {confidence:.2f}\")\n",
    "            \n",
    "            if confidence > best_confidence:\n",
    "                best_confidence = confidence\n",
    "                best_box = {\n",
    "                    'corners': box_points,\n",
    "                    'rect': rect,\n",
    "                    'border_lines': cluster1 + cluster2,\n",
    "                    'edge_lines': [edge1_a, edge1_b, edge2_a, edge2_b],\n",
    "                    'region_mask': region_mask\n",
    "                }\n",
    "    \n",
    "    if best_box is None:\n",
    "        print(\"\\nNo valid box found from border lines\")\n",
    "        return None\n",
    "    \n",
    "    # Extract results\n",
    "    corners = best_box['corners']\n",
    "    rect = best_box['rect']\n",
    "    center, (width, height), angle = rect\n",
    "    confidence = best_confidence\n",
    "    \n",
    "    area = width * height\n",
    "    area_ratio = area / img_area\n",
    "    \n",
    "    print(f\"\\n✓ Detection successful!\")\n",
    "    print(f\"  Confidence: {confidence:.2f}\")\n",
    "    print(f\"  Center: ({center[0]:.1f}, {center[1]:.1f})\")\n",
    "    print(f\"  Dimensions: {width:.1f} x {height:.1f}\")\n",
    "    print(f\"  Rotation: {angle:.1f}°\")\n",
    "    print(f\"  Area: {area_ratio*100:.1f}% of frame\")\n",
    "    \n",
    "    # Visualization\n",
    "    if visualize:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(24, 16))\n",
    "        \n",
    "        # 1. Original image\n",
    "        axes[0, 0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        axes[0, 0].set_title('Original Image', fontsize=14, fontweight='bold')\n",
    "        axes[0, 0].axis('off')\n",
    "        \n",
    "        # 2. Line canvas\n",
    "        axes[0, 1].imshow(line_canvas, cmap='gray')\n",
    "        axes[0, 1].set_title('All Detected Lines', fontsize=14, fontweight='bold')\n",
    "        axes[0, 1].axis('off')\n",
    "        \n",
    "        # 3. Negative space with regions\n",
    "        colored_regions = cv2.applyColorMap(\n",
    "            (labels * (255 // num_labels)).astype(np.uint8), \n",
    "            cv2.COLORMAP_JET\n",
    "        )\n",
    "        axes[0, 2].imshow(colored_regions)\n",
    "        axes[0, 2].set_title(f'Negative Space Regions ({num_labels-1} found)', \n",
    "                            fontsize=14, fontweight='bold')\n",
    "        axes[0, 2].axis('off')\n",
    "        \n",
    "        # 4. Selected region\n",
    "        axes[1, 0].imshow(best_box['region_mask'], cmap='gray')\n",
    "        axes[1, 0].set_title(f'Selected Smooth Region ({area_ratio*100:.1f}% of frame)', \n",
    "                            fontsize=14, fontweight='bold')\n",
    "        axes[1, 0].axis('off')\n",
    "        \n",
    "        # 5. Border lines with edge lines highlighted\n",
    "        img_border = image.copy()\n",
    "        # Draw all border lines in yellow\n",
    "        for line_data in best_box['border_lines']:\n",
    "            x1, y1, x2, y2 = line_data['line']\n",
    "            cv2.line(img_border, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "        # Draw the 4 selected edge lines in green\n",
    "        for edge_line in best_box['edge_lines']:\n",
    "            x1, y1, x2, y2 = edge_line\n",
    "            cv2.line(img_border, (x1, y1), (x2, y2), (0, 255, 0), 4)\n",
    "        axes[1, 1].imshow(cv2.cvtColor(img_border, cv2.COLOR_BGR2RGB))\n",
    "        axes[1, 1].set_title(f'Border Lines + 4 Edge Lines (green)', \n",
    "                            fontsize=14, fontweight='bold')\n",
    "        axes[1, 1].axis('off')\n",
    "        \n",
    "        # 6. Final detection\n",
    "        img_final = image.copy()\n",
    "        cv2.polylines(img_final, [corners.astype(np.int32)], True, (0, 255, 0), 4)\n",
    "        \n",
    "        for i, corner in enumerate(corners):\n",
    "            cv2.circle(img_final, tuple(corner.astype(int)), 12, (0, 0, 255), -1)\n",
    "            cv2.putText(img_final, str(i+1), tuple((corner - [5, -5]).astype(int)),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.putText(img_final, f'Confidence: {confidence:.2f}', \n",
    "                   (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)\n",
    "        cv2.putText(img_final, f'Angle: {angle:.1f} deg', \n",
    "                   (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)\n",
    "        cv2.putText(img_final, f'Area: {area_ratio*100:.1f}% of frame', \n",
    "                   (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)\n",
    "        \n",
    "        axes[1, 2].imshow(cv2.cvtColor(img_final, cv2.COLOR_BGR2RGB))\n",
    "        axes[1, 2].set_title('Final Detection', fontsize=14, fontweight='bold')\n",
    "        axes[1, 2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('negative_space_detection.png', dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"\\n✓ Visualization saved to negative_space_detection.png\")\n",
    "    \n",
    "    box_roi = RotatedBoxROI(\n",
    "        corners=corners,\n",
    "        center=center,\n",
    "        width=width,\n",
    "        height=height,\n",
    "        angle=angle,\n",
    "        confidence=confidence\n",
    "    )\n",
    "    \n",
    "    return box_roi\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = r\"C:\\Users\\jjmmc\\Documents\\FileTreeShenanigans\\output_image.jpeg\"\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"NEGATIVE SPACE DETECTION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    box_roi = detect_box_negative_space(image, min_area_ratio=1/10, visualize=True)\n",
    "    \n",
    "    if box_roi is not None:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"DETECTED CORNERS:\")\n",
    "        print(\"=\"*70)\n",
    "        for i, corner in enumerate(box_roi.corners):\n",
    "            print(f\"  Corner {i+1}: ({corner[0]:.1f}, {corner[1]:.1f})\")\n",
    "            \n",
    "            # Check if corner is out of bounds\n",
    "            h, w = image.shape[:2]\n",
    "            if corner[0] < 0 or corner[0] > w or corner[1] < 0 or corner[1] > h:\n",
    "                print(f\"    ⚠ WARNING: Corner {i+1} is outside image bounds!\")\n",
    "    else:\n",
    "        print(\"\\n✗ Detection failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabadd9d-c444-4928-a2fb-33ebaf7a37d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_video(input_path, output_path, start_time, end_time): \n",
    "    \"\"\"\n",
    "    Trims a video using ffmpeg from start_time to end_time. This could be modified for other video processing needs \n",
    "\n",
    "    :param input_path: Path to the input video file.\n",
    "    :param output_path: Desired output file name.\n",
    "    :param start_time: Start timestamp (e.g., \"00:01:00\").\n",
    "    :param end_time: End timestamp (e.g., \"00:02:00\").\n",
    "    \"\"\"\n",
    "    cmd = [\n",
    "        FFMPEG_path,\n",
    "        \"-y\", ##Overwrite\n",
    "        \"-ss\", str(start_time),\n",
    "        \"-to\", str(end_time),\n",
    "        \"-i\", input_path,\n",
    "        # \"-c\", \"copy\",  # This is tell ffmpeg to not reencode the video. This seems to be causing our import issue with sleap\n",
    "        \"-vf\", \"crop=800:ih:720:0\", # This crops the video essentially replacing the need to use handbrake. Cropping is done in a w:h:x:y format where w is width, h is height and x and y describe horizontal and vertical offsets respectively\n",
    "        output_path\n",
    "    ]\n",
    "    print(cmd)\n",
    "    TEST = [r\"C:\\Users\\June Means\\AppData\\Local\\ffmpeg-2025-06-28-git-cfd1f81e7d-full_build\\bin\\ffmpeg.exe\", \"-version\"]\n",
    "    subprocess.run(TEST, check=True)\n",
    "    try:\n",
    "        subprocess.run(cmd, check=True)\n",
    "        print(f\"Trimmed video saved to: {output_path}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error during ffmpeg execution:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23354581-2bf7-4614-9cd6-25c2ae9f0639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 735.15186   120.39032 ]\n",
      " [1356.2312     53.675934]\n",
      " [1454.019     964.03375 ]\n",
      " [ 832.9397   1030.7482  ]]\n",
      "works\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Negative Space ROI Detection for Behavioral Arenas\n",
    "\n",
    "Detects rectangular arenas by finding smooth regions (low edge density)\n",
    "surrounded by busy/textured backgrounds. Handles split arenas caused by\n",
    "lighting artifacts by merging adjacent regions.\n",
    "\n",
    "Usage:\n",
    "    roi, vis = detect_arena(image, known_aspect_ratio=1.5, visualize=True)\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Optional, List\n",
    "\n",
    "# The path you want to add. Use absolute paths for reliability.\n",
    "new_path = R\"C:\\Users\\jjmmc\\Downloads\"\n",
    "\n",
    "# Append the new path to sys.path\n",
    "sys.path.append(new_path)\n",
    "\n",
    "from negative_space_roi import detect_arena\n",
    "\n",
    "\n",
    "image_path = r\"C:\\Users\\jjmmc\\Documents\\FileTreeShenanigans\\output_image.jpeg\"\n",
    "image = cv2.imread(image_path)\n",
    "roi, vis = detect_arena(\n",
    "    image,\n",
    "    known_aspect_ratio=1.5,  # Close to 1.47\n",
    "    min_area_ratio=0.18,\n",
    "    max_area_ratio=0.30,\n",
    "    aspect_tolerance=0.20,\n",
    "    density_threshold=20,\n",
    "    visualize=True\n",
    ")\n",
    "if roi:\n",
    "    corners = roi.corners  # 4x2 numpy array\n",
    "    mask = roi.get_mask(image.shape)\n",
    "\n",
    "print(corners)\n",
    "if vis is not None:\n",
    "    print(\"works\")\n",
    "    cv2.imwrite(\"detection_debug.jpg\", vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5603d00c-0d5b-4382-a3f4-2f6c6976b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nest_calculator(f_pts, percent_of_perspective=0.1955, buffer=40):\n",
    "    \"\"\"\n",
    "    This is a hard coded calculation of where the nest should be given the floor's corners. \n",
    "    The rectange's points are defined as\n",
    "\n",
    "    0-1\n",
    "    | |\n",
    "    3-2\n",
    "    \"\"\"\n",
    "    nest_rect = np.zeros((4,2))\n",
    "    side_vector = f_pts[0]-f_pts[1]\n",
    "    side_vector = sidevector / np.linalg.norm(side_vector)\n",
    "    up_vector = np.rot90(side_vector)\n",
    "    nest_rect[0] = percent_of_perspective*f_pts[0] +(1-percent_of_perspective) * f_pts[3] +side_vector*20 # Find the point ~20% from the bottom left to top left and then shift it over 20 units left perpendicularly\n",
    "    nest_rect[2]= f_pts[2]- buffer*side_vector-buffer*up_vector\n",
    "    nest_rect[3]= f_pts[3]+ buffer*side_vector-buffer*up_vector\n",
    "    nest_rect[1]= nest_rect[0]+nest_rect[2]-nest_rect[3] #take the vector from 3 to 2 and add it to 1 to obtain the remaining point\n",
    "    return(nest_rect)\n",
    "\n",
    "def loom_calculator(f_pts, percent_of_perspective=0.1506, radius =32):\n",
    "    loom_circle = np.zeros(2)\n",
    "    loom_circle[1]= radius\n",
    "    \n",
    "    down_vector = f_pts[3]-f_pts[0]\n",
    "    loom_circle[0]= 0.5*(f_pts[0]+f_pts[1])+(down_vector*percent_of_perspective)\n",
    "\n",
    "    return(loom_circle)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
