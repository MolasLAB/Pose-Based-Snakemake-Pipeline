{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c32d170-546c-496c-9e40-70d72fed921d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import csv\n",
    "import math as m\n",
    "import numpy as np\n",
    "#import pandas as pd \n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f935ac02-228b-4521-bc9e-85a86956f5eb",
   "metadata": {},
   "source": [
    "#### READ ME ####\n",
    "\n",
    "The purpose of this code is to take incomplete SLEAP data and complete it to make sure that there are no missed identities or parts and make sure that the position data is in such a form as to allow easy interpretation for feature extraction. I conceptualized this problem as working down the line of data with a small context window to make sure everything is in order. Procedurally this script should go down the whole list multiple times first finding missing identities, filling them, reordering things so that identities are consistant, merging identities, and then interpolating pointsso that we have two continuous paths in space. Also as of the 15th of January there are still a few things I need to do.\n",
    "\n",
    "This is a different version of the script that takes the prediction on singles with a max identity set to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b107cf9-866c-4b8f-8571-7ebb93d63b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "## This is a search script that will find the files that match a pattern in the directory and return said matches\n",
    "\n",
    "Rootdir= 'C:/Users/Public/SLEAP/SingleBehavior CSV/Uncleaned' # replace this the scope of the search\n",
    "OutputPath= os.getcwd() # can be replaced with a dedicated path ie 'C:/Users/Jume6823.AD.000/Downloads'\n",
    "\n",
    "#SinglePattern= \"L\\d{1}\\sTrap2\\d{3}.analysis$\"\n",
    "#PairPattern = \"L\\d{1}\\sTrap2\\d{3}[+]\\d{3}.analysis$\"\n",
    "\n",
    "def CSVSearch(sex:str, RootDir, Pair:bool):\n",
    "    if Pair == 0:\n",
    "        pattern= re.compile(r'L\\d{1}\\sTrap2\\d{3}.analysis')\n",
    "    else:\n",
    "        pattern= re.compile(r'L\\d{1}\\sTrap2\\d{3}[-+]\\d{3}.analysis')\n",
    "        print('hey')\n",
    "    \n",
    "    matching = []\n",
    "    for path, directories, files in os.walk(RootDir):\n",
    "        \n",
    "        for file in files:\n",
    "            if pattern.search(file):\n",
    "                filepath= (path+os.sep+file).replace(\"\\\\\",\"/\")\n",
    "                matching.append(filepath)\n",
    "    return(matching)\n",
    "\n",
    "def CSVSearch2(RootDir, Pair:bool):\n",
    "    if Pair == 0:\n",
    "        pattern= re.compile(r'L\\d{1}\\sTrap2\\d{3}.analysis')\n",
    "    else:\n",
    "        pattern= re.compile(r'L\\d{1}\\sTrap2\\d{3}[-+]\\d{3}.analysis')\n",
    "        print('hey')\n",
    "    \n",
    "    matching = []\n",
    "    for path, directories, files in os.walk(RootDir):\n",
    "        for file in files:\n",
    "            filepath= (path+os.sep+file).replace(\"\\\\\",\"/\")\n",
    "            matching.append(filepath)\n",
    "    return(matching)\n",
    "\n",
    "Singles = CSVSearch2(Rootdir,0)\n",
    "print(len(Singles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "863b0e5b-08f7-4be7-8dca-ac831aae8263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/Users/Public/SLEAP/SingleBehavior CSV/Uncleaned/SingleBehaviorSURF.000_20241028 Trap2social 5Vls M L1 Trap2168.analysis.csv', 'C:/Users/Public/SLEAP/SingleBehavior CSV/Uncleaned/SingleBehaviorSURF.001_20241101 Trap2social 5Vls M L5 Trap2155.analysis.csv', 'C:/Users/Public/SLEAP/SingleBehavior CSV/Uncleaned/SingleBehaviorSURF.002_20241113 Trap2social 5Vls F L1 Trap2158.analysis.csv', 'C:/Users/Public/SLEAP/SingleBehavior CSV/Uncleaned/SingleBehaviorSURF.003_20241115 Trap2social 5Vls F L3 Trap2158.analysis.csv', 'C:/Users/Public/SLEAP/SingleBehavior CSV/Uncleaned/SingleBehaviorSURF.004_20241115 Trap2social 5Vls F L3 Trap2161.analysis.csv', 'C:/Users/Public/SLEAP/SingleBehavior CSV/Uncleaned/SingleBehaviorSURF.005_20241118 Day3 327.analysis.csv', 'C:/Users/Public/SLEAP/SingleBehavior CSV/Uncleaned/SingleBehaviorSURF.006_20241120 Wt 5Vls Day5 C57338.analysis.csv', 'C:/Users/Public/SLEAP/SingleBehavior CSV/Uncleaned/SingleBehaviorSURF.007_20250228 Trap2 Social 5Vls Day5 237.analysis.csv', 'C:/Users/Public/SLEAP/SingleBehavior CSV/Uncleaned/SingleBehaviorSURF.008_20250319 Tam Control 5Vls Day3 Trap2 251.analysis.csv', 'C:/Users/Public/SLEAP/SingleBehavior CSV/Uncleaned/SingleBehaviorSURF.009_20250320 Tam Control 5Vls Day4 Trap2 248.analysis.csv']\n"
     ]
    }
   ],
   "source": [
    "print(Singles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afe3ffda-db87-497e-9af9-f936b7634525",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This section of the code is for taking the csv files from the sleap labels and then just making it into a list I can work with \n",
    "numberofpoints= 6\n",
    "pointlist = [[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0]]\n",
    "def FrameDistance(A,B): ### just taking the euclidiean distance of the distances between body points of the same type\n",
    "    NoseD= m.dist([A[1][0],A[1][1]],[B[1][0],B[1][1]])\n",
    "    EarLD= m.dist([A[2][0],A[2][1]],[B[2][0],B[2][1]])\n",
    "    EarRD= m.dist([A[3][0],A[3][1]],[B[3][0],B[3][1]])\n",
    "    HeadD =m.dist([A[4][0],A[4][1]],[B[4][0],B[4][1]])\n",
    "    CenterD= m.dist([A[5][0],A[5][1]],[B[5][0],B[5][1]])\n",
    "    TailD= m.dist([A[6][0],A[6][1]],[B[6][0],B[6][1]])\n",
    "    TotalD= NoseD**2+EarLD**2+EarRD**2+HeadD**2+CenterD**2+TailD**2\n",
    "    return(TotalD)\n",
    "\n",
    "\n",
    "def SingleIdentityTracker(index):\n",
    "    with open(Singles[index], 'r') as csvfile:\n",
    "        pointreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        row_count= sum(1 for row in pointreader)\n",
    "        \n",
    "    ### Why these blocks have to be seperate I don't know but it works and I should probably switch to Pandas anyways but here we are\n",
    "    \n",
    "    with open(Singles[index], 'r') as csvfile:\n",
    "        pointreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        #print(sum(1 for row in pointreader))\n",
    "    \n",
    "        ### The first two variables are the instance and frame respectively, from there the coordinates of the nose earL, earR, head, body center and tail base\n",
    "        pointlist = [[[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0]] for i in range(row_count)]\n",
    "        j=0\n",
    "        ### This is just copying over the first row\n",
    "        FirstRow = next(pointreader)\n",
    "        #print(FirstRow)\n",
    "        #print(len(FirstRow))\n",
    "        ### This is just making a new list that is more easy to work with\n",
    "        for row in pointreader:\n",
    "            i=0\n",
    "            for col in row:\n",
    "                if j !=-1:\n",
    "                    ### The first index is for the track which is a string by default weirdly enough\n",
    "                    if i == 0:\n",
    "                        pointlist[j][0][0]= int(''.join([char for char in col[::-1] if char.isdigit()])[::-1]) ##this just grabs the last digits in the string\n",
    "                    if i == 1:\n",
    "                        pointlist[j][0][1]= int(col)\n",
    "                    if i % 3 == 0 and i!=0:   \n",
    "                        if col !='':\n",
    "                            pointlist[j][int(i/3)][0]= float(col)\n",
    "                    if i % 3 == 1 and i!=1:\n",
    "                        if col !='':\n",
    "                            pointlist[j][int((i-1)/3)][1]= float(col)\n",
    "                    if i % 3 == 2:\n",
    "                        if col !='':\n",
    "                            pointlist[j][int((i-1)/3)][2]= float(col)\n",
    "                i=i+1\n",
    "            j=j+1\n",
    "        #print(j)\n",
    "        \n",
    "        \n",
    "        ### This checks for missing identities\n",
    "        \n",
    "        MissingId = []\n",
    "        currentframe = 0\n",
    "        for i in range(len(pointlist)-1):\n",
    "            if pointlist[i][0][1] == currentframe:\n",
    "                currentframe += 1\n",
    "            else:\n",
    "                for j in range(pointlist[i][0][1]-currentframe):\n",
    "                    MissingId.append([i,currentframe, pointlist[i][0][1]])\n",
    "                    currentframe += 1\n",
    "                currentframe +=1\n",
    "        NewPointList= pointlist\n",
    "        \n",
    "        #print(MissingId)\n",
    "        #print(len(MissingId), \"identities are missing \")\n",
    "        for i in reversed(range(len(MissingId))):\n",
    "            ### this just makes sure that the id we are putting back is the correct one and not the one picked up earlier \n",
    "            NewPointList.insert(MissingId[i][0],[[MissingId[i][2],MissingId[i][1],0.0],[0.0,0.0,0.0],[0.0,0.0,0.0],[0.0,0.0,0.0],[0.0,0.0,0.0],[0.0,0.0,0.0],[0.0,0.0,0.0]])\n",
    "        i=0\n",
    "        \n",
    "        #print(NewPointList[2])\n",
    "        ### This is then linearly bridging any missing values by going along the array until a problem point is detected and then tracing back to the last entry and then foward until the next unempty entry and then interpolating the points linearly\n",
    "        for i in range(len(NewPointList)):\n",
    "            for j in range(6):\n",
    "                ### This checks if there are any zero entries in the list\n",
    "                if NewPointList[i][j+1][0] == 0.0 or NewPointList[i][j+1][1] == 0.0:\n",
    "                    anchor = NewPointList[i-1][j+1]\n",
    "                    #print(\"anchor is\" + str(anchor))\n",
    "                    scope = i\n",
    "                    ### This looks forward for the next valid point going every row\n",
    "                    while scope < (len(NewPointList)-1):\n",
    "                        scope += 1\n",
    "                        if NewPointList[scope][j+1][0] != 0.0:\n",
    "                            endpoint = NewPointList[scope][j+1]\n",
    "                            #print([j,i,scope,endpoint])\n",
    "                            length = int(scope-i)\n",
    "                            #print(length)\n",
    "                            break \n",
    "                    ### This is for the weird case in which there is no endpoint and so then we  just go backwards and find the last valid point and copy it over. We should discuss with Dr. Molas if instead the data should be cropped in that case.\n",
    "                    else:\n",
    "                        #print(\"endpoint missing starting from \" + str(i))\n",
    "                        backscope = i\n",
    "                        while backscope <= (len(NewPointList)):\n",
    "                            backscope -= 1\n",
    "                            if NewPointList[backscope][j+1][0] != 0.0:\n",
    "                                endpoint = NewPointList[backscope][j+1]\n",
    "                                ## This just tells the next function to take the rest of the missing values and fill them in with the last found value\n",
    "                                length = int((len(NewPointList))-i)\n",
    "                                break \n",
    "                    #print(anchor,endpoint)\n",
    "                    ### This is simply a linear interpolation of points. Other ways of fittig could also be used here.\n",
    "                    for k in range(length):\n",
    "                        ratio= (k+1)/(length+1)\n",
    "                        NewPointList[i+(k)][j+1][0]= anchor[0]*(1-ratio)+endpoint[0]*ratio\n",
    "                        NewPointList[i+(k)][j+1][1]= anchor[1]*(1-ratio)+endpoint[1]*ratio\n",
    "                        NewPointList[i+(k)][j+1][2]= anchor[2]*(1-ratio)+endpoint[2]*ratio\n",
    "                    TempList = []\n",
    "                    for k in range(length):\n",
    "                        TempList.append(NewPointList[i+(k)][j+1][0])\n",
    "                    \n",
    "                    #print(i+length)\n",
    "        pointlist=NewPointList\n",
    "        NewNameIndex= Singles[index].rfind('_')\n",
    "        #print(NewNameIndex)\n",
    "        NewName= Singles[index][NewNameIndex+1:]\n",
    "        print(NewName)\n",
    "        #print(pointlist[0])\n",
    "        data = [FirstRow]\n",
    "        with open(OutputPath+os.sep+NewName, 'w', newline ='') as f:\n",
    "            ### Not fully sure what dialect to use here(a dialect is essentially different protocols for interpreting csv) but excel should be fine I imagine.\n",
    "            writer = csv.writer(f,dialect='excel')\n",
    "            \n",
    "            #for row in pointreader:\n",
    "              #  new_row = row \n",
    "              #  writer.writerow(new_row)\n",
    "            j=0\n",
    "            ## Just skipping the first 0 line\n",
    "            for i in range(len(pointlist)-1):\n",
    "                data.append([0] * 21)\n",
    "                data[i+1][0]= 'track_0' ## He we force it be 1 identity\n",
    "                data[i+1][1]= pointlist[i][0][1]\n",
    "                data[i+1][2]= pointlist[i][0][2]\n",
    "                for j in range(6):\n",
    "                    data[i+1][3+(3*j)] = pointlist[i][j+1][0]\n",
    "                    data[i+1][4+(3*j)] = pointlist[i][j+1][1]\n",
    "                    data[i+1][5+(3*j)] = pointlist[i][j+1][2]\n",
    "            #print(data[0])\n",
    "            #print(data[1])\n",
    "            writer.writerows(data)\n",
    "            #print(MissingId)\n",
    "            #print(len(MissingId), \"identities are missing \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "798abf43-93db-4889-9b0c-b94362d0c75c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20241028 Trap2social 5Vls M L1 Trap2168.analysis.csv\n",
      "20241101 Trap2social 5Vls M L5 Trap2155.analysis.csv\n",
      "20241113 Trap2social 5Vls F L1 Trap2158.analysis.csv\n",
      "20241115 Trap2social 5Vls F L3 Trap2158.analysis.csv\n",
      "20241115 Trap2social 5Vls F L3 Trap2161.analysis.csv\n",
      "20241118 Day3 327.analysis.csv\n",
      "20241120 Wt 5Vls Day5 C57338.analysis.csv\n",
      "20250228 Trap2 Social 5Vls Day5 237.analysis.csv\n",
      "20250319 Tam Control 5Vls Day3 Trap2 251.analysis.csv\n",
      "20250320 Tam Control 5Vls Day4 Trap2 248.analysis.csv\n"
     ]
    }
   ],
   "source": [
    "#### Run up to this block\n",
    "for i in range(len(Singles)):\n",
    "    SingleIdentityTracker(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
